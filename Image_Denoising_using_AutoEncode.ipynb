{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 735991,
          "sourceType": "datasetVersion",
          "datasetId": 379454
        }
      ],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Image Denoising using AutoEncoder (PyTorchðŸ”¥)",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaurav14cs17/DeNoisingHomogeneous-Region/blob/main/Image_Denoising_using_AutoEncode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "greatgamedota_ffhq_face_data_set_path = kagglehub.dataset_download('greatgamedota/ffhq-face-data-set')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "XglJq6FJfLmb"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"font-size:18px;\">A note before starting, this notebook was run locally using GPU and due to the long time it would take to be executed again I'll be copying some of the outputs from the local notebook and put them in markdown. I hope you find the notebook beneficial, and if you have any piece of advice feel free to share it in the comments."
      ],
      "metadata": {
        "id": "BiCzcM00fLme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "yocrJ6LYfLmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"font-size:18px;\"> The context of this notebook is an academic project where we were demanded to denoise images (without specifying the method). In the beginning I tried a non-ML solution that is called BM3D (Block Matching and 3D filtering), then I went ahead to experiment with the Deep Learning approach using the Auto-Encoder architecture."
      ],
      "metadata": {
        "id": "11d9m8plfLmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the notebook"
      ],
      "metadata": {
        "tags": [],
        "id": "43ug-gdYfLmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "!pip install bm3d\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import bm3d\n",
        "\n",
        "import torch.cuda\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear, ReLU, MSELoss, L1Loss, Sequential, Conv2d, ConvTranspose2d, MaxPool2d, AdaptiveAvgPool2d, Module, BatchNorm2d, Sigmoid, Dropout\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import datasets, transforms\n",
        "import os"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-06T17:41:52.206241Z",
          "iopub.execute_input": "2025-08-06T17:41:52.207119Z"
        },
        "id": "tupg2AsRfLmh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "T9mtt7QxfLmj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "greatgamedota_ffhq_face_data_set_path"
      ],
      "metadata": {
        "trusted": true,
        "id": "J-efzF5IfLmj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "CTZva9G2fLmk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Device cuda"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-21T18:48:32.907909Z",
          "iopub.execute_input": "2022-02-21T18:48:32.908281Z",
          "iopub.status.idle": "2022-02-21T18:48:32.937685Z",
          "shell.execute_reply.started": "2022-02-21T18:48:32.908184Z",
          "shell.execute_reply": "2022-02-21T18:48:32.936759Z"
        },
        "id": "zUTdG6BWfLmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"font-size:18px;\">I downloaded and used the dataset available in this link : https://www.kaggle.com/greatgamedota/ffhq-face-data-set"
      ],
      "metadata": {
        "id": "jgvQH6VjfLmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH =  \"/root/.cache/kagglehub/datasets/greatgamedota/ffhq-face-data-set/versions/2\""
      ],
      "metadata": {
        "trusted": true,
        "id": "IeKYqdN3fLml"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = PATH\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize(256),\n",
        "                                transforms.ToTensor()\n",
        "                               ])\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "lengths = [int(len(dataset)*0.8), int(len(dataset)*0.2)]\n",
        "train_dataset, val_dataset = random_split(dataset, lengths)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "y7MRJYX3fLml"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax"
      ],
      "metadata": {
        "trusted": true,
        "id": "906kA5eAfLml"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing an image from the dataset\n",
        "images, _ = next(iter(val_dataloader))\n",
        "imshow(images[1], normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "hDXSopaAfLml"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Expermenting with the noises"
      ],
      "metadata": {
        "tags": [],
        "id": "FBdmbsZ1fLml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "White Additive Noise :"
      ],
      "metadata": {
        "id": "N8fOTM79fLmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_images = (images + torch.normal(0,0.2, images.shape)).clip(0,1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "sYp1v6p1fLmm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(noisy_images[1], normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "54-DfxI7fLmm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Masking Noise :"
      ],
      "metadata": {
        "id": "1BOaNeTxfLmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 0.7*torch.ones(images.shape)\n",
        "bernouilli_noisy_images = images*torch.bernoulli(a)"
      ],
      "metadata": {
        "trusted": true,
        "id": "NSVxWNizfLmm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(bernouilli_noisy_images[1], normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "LdusZGVufLmn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Poisson Noise :"
      ],
      "metadata": {
        "id": "VPpLakNqfLmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 5*torch.ones(images.shape)\n",
        "p = torch.poisson(a)\n",
        "p_norm = p/p.max()"
      ],
      "metadata": {
        "trusted": true,
        "id": "PiPemsGjfLmn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "poisson_noisy_images = (images + p_norm).clip(0,1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "q6Dlhn-1fLmn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(poisson_noisy_images[1], normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "hO1kBUi6fLmn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "EPS = 1e-8"
      ],
      "metadata": {
        "trusted": true,
        "id": "lcn_Rxt1fLmn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"font-size:18px;\"> These are some helper functions to evaluate the the performance of the denoising approachs:"
      ],
      "metadata": {
        "id": "-nLz-YyZfLmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PSNR(input, target):\n",
        "    return -10*torch.log10(torch.mean((input - target) ** 2, dim=[1, 2, 3])+EPS)"
      ],
      "metadata": {
        "trusted": true,
        "id": "mMAXDuxzfLmn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE(input, target):\n",
        "    return torch.mean((input - target) ** 2, dim=[1, 2, 3])"
      ],
      "metadata": {
        "trusted": true,
        "id": "jSKIpqDafLmo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "PSNR of Normal Noise Images :"
      ],
      "metadata": {
        "id": "CdhxhOT2fLmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PSNR(images, noisy_images)"
      ],
      "metadata": {
        "trusted": true,
        "id": "kZ78jYdKfLmo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor([15.0455, 15.1718, 14.7140, 14.7304, 15.3507, 15.3572, 14.9787, 14.8285,\n",
        "        14.7231, 14.9067, 15.6183, 14.5245, 14.7026, 15.0107, 14.9028, 14.9212])"
      ],
      "metadata": {
        "id": "79sfky3PfLmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PSNR of Masked Images :"
      ],
      "metadata": {
        "id": "f03i9ehjfLmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PSNR(images, bernouilli_noisy_images)"
      ],
      "metadata": {
        "trusted": true,
        "id": "JKUcFjhFfLmo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor([10.7218, 13.6338, 12.5109, 11.8838, 11.0169,  7.7124, 10.1220, 12.0363,\n",
        "        11.0440,  9.5477, 16.9152,  9.7393, 11.7690, 10.0014,  9.8994, 12.6178])"
      ],
      "metadata": {
        "id": "zXz59uyafLmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PSNR of Poisson Noise Images :"
      ],
      "metadata": {
        "id": "fb-LzlTMfLmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PSNR(images, poisson_noisy_images)"
      ],
      "metadata": {
        "trusted": true,
        "id": "mJMVVSMRfLmp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor([11.7429, 10.9976, 11.1412, 11.1908, 11.7629, 13.7808, 11.9429, 11.2966,\n",
        "        11.3740, 12.1885, 10.8384, 11.8166, 11.2383, 12.0369, 12.0351, 11.1616])"
      ],
      "metadata": {
        "id": "boZkKpCPfLmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"font-size:18px;\">So these scores represent a baseline for us, the models that we will create need to have a significantly higher PSNR to be taken into consideration."
      ],
      "metadata": {
        "id": "RfCG220OfLmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Denoising using BM3D"
      ],
      "metadata": {
        "tags": [],
        "id": "_U-vVyctfLmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "denoised_image = bm3d.bm3d(noisy_images[1].permute(1,2,0), sigma_psd=30/255, stage_arg=bm3d.BM3DStages.HARD_THRESHOLDING)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ELmVqGlJfLmv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(denoised_image)"
      ],
      "metadata": {
        "trusted": true,
        "id": "pIpSwN13fLmv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "bernouilli_denoised_image = bm3d.bm3d(bernouilli_noisy_images[1].permute(1,2,0), sigma_psd=30/255, stage_arg=bm3d.BM3DStages.HARD_THRESHOLDING)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Evn6vEowfLmv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(bernouilli_denoised_image)"
      ],
      "metadata": {
        "trusted": true,
        "id": "nOefnLaLfLmv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "poisson_denoised_image = bm3d.bm3d(poisson_noisy_images[1].permute(1,2,0), sigma_psd=15/255, stage_arg=bm3d.BM3DStages.HARD_THRESHOLDING).clip(0,1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "uJL5XyMAfLmv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(poisson_denoised_image)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Nx1DViIcfLmv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"font-size:18px;\">The BM3D method has given a significant improvement when used for the normal noise, but for the other two noises it wasn't as remarkable."
      ],
      "metadata": {
        "id": "YBSv-GJRfLmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"font-size:18px;\">(You can find a comparative illustrative in the end of the notebook)"
      ],
      "metadata": {
        "id": "8V6P4HhFfLmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Denoising using Deep Learning"
      ],
      "metadata": {
        "tags": [],
        "id": "XygjN1YJfLmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoencoders"
      ],
      "metadata": {
        "tags": [],
        "id": "iGowybqgfLmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.init import kaiming_normal_\n",
        "\n",
        "class HaarDWT(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        # Orthonormal Haar wavelet kernels\n",
        "        ll = torch.tensor([[1, 1], [1, 1]], dtype=torch.float32) * 0.5\n",
        "        lh = torch.tensor([[1, -1], [1, -1]], dtype=torch.float32) * 0.5\n",
        "        hl = torch.tensor([[1, 1], [-1, -1]], dtype=torch.float32) * 0.5\n",
        "        hh = torch.tensor([[1, -1], [-1, 1]], dtype=torch.float32) * 0.5\n",
        "\n",
        "        kernel = torch.stack([ll, lh, hl, hh], dim=0).unsqueeze(1)\n",
        "        self.register_buffer('filters', kernel.repeat(in_channels, 1, 1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Symmetric padding for perfect reconstruction\n",
        "        x = F.pad(x, (1, 0, 1, 0), mode='reflect')\n",
        "        return F.conv2d(x, self.filters, stride=2, groups=self.in_channels)\n",
        "\n",
        "class HaarIDWT(nn.Module):\n",
        "    def __init__(self, out_channels):\n",
        "        super().__init__()\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # Adjoint operators for perfect reconstruction\n",
        "        ll = torch.tensor([[1, 1], [1, 1]], dtype=torch.float32) * 0.5\n",
        "        lh = torch.tensor([[1, 1], [-1, -1]], dtype=torch.float32) * 0.5\n",
        "        hl = torch.tensor([[1, -1], [1, -1]], dtype=torch.float32) * 0.5\n",
        "        hh = torch.tensor([[1, -1], [-1, 1]], dtype=torch.float32) * 0.5\n",
        "\n",
        "        kernel = torch.stack([ll, lh, hl, hh], dim=0).unsqueeze(1)\n",
        "        self.register_buffer('inv_filters', kernel.repeat(out_channels, 1, 1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Matching padding for perfect reconstruction\n",
        "        x = F.pad(x, (0, 1, 0, 1), mode='reflect')\n",
        "        return F.conv_transpose2d(x, self.inv_filters, stride=2, groups=self.out_channels)\n",
        "\n",
        "class PerfectReconstructionTest(nn.Module):\n",
        "    \"\"\"Module to verify perfect reconstruction property\"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.dwt = HaarDWT(channels)\n",
        "        self.idwt = HaarIDWT(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        coeffs = self.dwt(x)\n",
        "        return self.idwt(coeffs)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Conv2d(channels, channels, 3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv(x)\n",
        "\n",
        "class FrequencyAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(channels, channels//4, 1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Conv2d(channels//4, channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.fc(x)\n",
        "\n",
        "class EdgeAwareDenoiser(nn.Module):\n",
        "    def __init__(self, in_channels, base_channels=32):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, base_channels, 3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True)\n",
        "        )\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Conv2d(base_channels, base_channels*2, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True)\n",
        "        )\n",
        "        self.enc3 = nn.Sequential(\n",
        "            nn.Conv2d(base_channels*2, base_channels*4, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True)\n",
        "        )\n",
        "\n",
        "        # Bottleneck with attention\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            ResidualBlock(base_channels*4),\n",
        "            FrequencyAttention(base_channels*4),\n",
        "            ResidualBlock(base_channels*4)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.dec3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(base_channels*4, base_channels*2, 2, stride=2),\n",
        "            nn.LeakyReLU(0.1, inplace=True)\n",
        "        )\n",
        "        self.dec2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(base_channels*4, base_channels, 2, stride=2),\n",
        "            nn.LeakyReLU(0.1, inplace=True)\n",
        "        )\n",
        "        self.dec1 = nn.Conv2d(base_channels*2, in_channels, 3, padding=1)\n",
        "\n",
        "        # Edge enhancement\n",
        "        self.edge_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels, 3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Conv2d(in_channels, in_channels, 3, padding=1)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "                kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # Apply frequency mask\n",
        "        x = x * mask\n",
        "\n",
        "        # Encoder path\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(e1)\n",
        "        e3 = self.enc3(e2)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(e3)\n",
        "\n",
        "        # Decoder path with skip connections\n",
        "        d3 = self.dec3(b)\n",
        "        d2 = self.dec2(torch.cat([d3, e2], dim=1))\n",
        "        d1 = self.dec1(torch.cat([d2, e1], dim=1))\n",
        "\n",
        "        # Edge-aware refinement\n",
        "        edges = self.edge_conv(x)\n",
        "        return d1 + edges\n",
        "\n",
        "class DWT2DenoisingModel(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        # Wavelet transforms\n",
        "        self.dwt1 = HaarDWT(in_channels)\n",
        "        self.dwt2 = HaarDWT(in_channels)\n",
        "        self.idwt2 = HaarIDWT(in_channels)\n",
        "        self.idwt1 = HaarIDWT(in_channels)\n",
        "\n",
        "        # Low-frequency processor\n",
        "        self.ll_processor = nn.Sequential(\n",
        "            ResidualBlock(in_channels),\n",
        "            FrequencyAttention(in_channels),\n",
        "            ResidualBlock(in_channels)\n",
        "        )\n",
        "\n",
        "        # Edge and flatness detection\n",
        "        self.edge_detector = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels//2, 3, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Conv2d(in_channels//2, 1, 3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Main denoiser\n",
        "        self.denoiser = EdgeAwareDenoiser(in_channels=6*in_channels)\n",
        "\n",
        "        # Initialize\n",
        "        self._initialize_weights()\n",
        "        self.recon_test = PerfectReconstructionTest(in_channels)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def compute_frequency_mask(self, ll_band):\n",
        "        # Flatness mask\n",
        "        mean = F.avg_pool2d(ll_band, 3, stride=1, padding=1)\n",
        "        variance = (ll_band - mean).pow(2)\n",
        "        flatness = 1 - torch.tanh(variance.mean(dim=1, keepdim=True) * 5\n",
        "\n",
        "        # Edge mask\n",
        "        edges = self.edge_detector(ll_band)\n",
        "\n",
        "        # Combined mask\n",
        "        return torch.sigmoid(flatness + edges)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        # Pad to multiples of 4\n",
        "        pad_h = (4 - H % 4) % 4\n",
        "        pad_w = (4 - W % 4) % 4\n",
        "        x_pad = F.pad(x, (0, pad_w, 0, pad_h), mode='reflect')\n",
        "\n",
        "        # Level 1 decomposition\n",
        "        dwt1_out = self.dwt1(x_pad)\n",
        "        LL1, LH1, HL1, HH1 = torch.chunk(dwt1_out, 4, dim=1)\n",
        "\n",
        "        # Level 2 decomposition\n",
        "        dwt2_out = self.dwt2(LL1)\n",
        "        LL2, LH2, HL2, HH2 = torch.chunk(dwt2_out, 4, dim=1)\n",
        "\n",
        "        # Process LL band\n",
        "        LL2_processed = self.ll_processor(LL2)\n",
        "\n",
        "        # Compute frequency-aware mask\n",
        "        freq_mask = self.compute_frequency_mask(LL2_processed)\n",
        "\n",
        "        # Prepare denoiser input\n",
        "        denoiser_input = torch.cat([\n",
        "            LH2 * freq_mask,\n",
        "            HL2 * freq_mask,\n",
        "            HH2 * freq_mask,\n",
        "            F.interpolate(LH1, scale_factor=0.5, mode='bilinear') * freq_mask,\n",
        "            F.interpolate(HL1, scale_factor=0.5, mode='bilinear') * freq_mask,\n",
        "            F.interpolate(HH1, scale_factor=0.5, mode='bilinear') * freq_mask\n",
        "        ], dim=1)\n",
        "\n",
        "        # Denoise high frequencies\n",
        "        denoised = self.denoiser(denoiser_input, freq_mask)\n",
        "        den_LH2, den_HL2, den_HH2, den_LH1, den_HL1, den_HH1 = torch.chunk(denoised, 6, dim=1)\n",
        "\n",
        "        # Reconstruct level 2\n",
        "        idwt2_in = torch.cat([LL2_processed, den_LH2, den_HL2, den_HH2], dim=1)\n",
        "        LL1_recon = self.idwt2(idwt2_in)\n",
        "\n",
        "        # Reconstruct level 1\n",
        "        idwt1_in = torch.cat([\n",
        "            LL1_recon,\n",
        "            F.interpolate(den_LH1, size=LL1_recon.shape[-2:], mode='bilinear'),\n",
        "            F.interpolate(den_HL1, size=LL1_recon.shape[-2:], mode='bilinear'),\n",
        "            F.interpolate(den_HH1, size=LL1_recon.shape[-2:], mode='bilinear')\n",
        "        ], dim=1)\n",
        "\n",
        "        recon = self.idwt1(idwt1_in)\n",
        "\n",
        "        # Crop to original size\n",
        "        return recon[:, :, :H, :W]\n",
        "\n",
        "class MultiScaleLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "        # Sobel filters for edge detection\n",
        "        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).view(1, 1, 3, 3)\n",
        "        sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32).view(1, 1, 3, 3)\n",
        "        self.register_buffer('sobel_x', sobel_x)\n",
        "        self.register_buffer('sobel_y', sobel_y)\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        # Pixel-level loss\n",
        "        mse_loss = self.mse(output, target)\n",
        "\n",
        "        # Edge loss\n",
        "        def sobel(t):\n",
        "            gx = F.conv2d(t, self.sobel_x.repeat(t.size(1), 1, 1, 1), padding=1, groups=t.size(1))\n",
        "            gy = F.conv2d(t, self.sobel_y.repeat(t.size(1), 1, 1, 1), padding=1, groups=t.size(1))\n",
        "            return torch.sqrt(gx**2 + gy**2 + 1e-6)\n",
        "\n",
        "        edge_loss = F.l1_loss(sobel(output), sobel(target))\n",
        "\n",
        "        # Frequency loss\n",
        "        dwt = HaarDWT(3)\n",
        "        out_coeffs = dwt(output)\n",
        "        tgt_coeffs = dwt(target)\n",
        "        freq_loss = sum(F.mse_loss(o, t) for o, t in zip(out_coeffs, tgt_coeffs))\n",
        "\n",
        "        return mse_loss + 0.3 * edge_loss + 0.2 * freq_loss\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "RE3EtyFvfLmw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loss_module = MultiScaleLoss()"
      ],
      "metadata": {
        "trusted": true,
        "id": "sY6XBgxxfLmx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, val_dataloader, noise_type, noise_parameter):\n",
        "    model.eval()\n",
        "    psnr = []\n",
        "    mse = []\n",
        "    with torch.no_grad():\n",
        "        for images, _ in val_dataloader:\n",
        "            if (noise_type == \"normal\"):\n",
        "                noisy_images = (images + torch.normal(0,noise_parameter,images.shape)).clip(0,1)\n",
        "            elif (noise_type == \"bernoulli\"):\n",
        "                a = noise_parameter*torch.ones(images.shape)\n",
        "                noisy_images = images*torch.bernoulli(a)\n",
        "            elif (noise_type == \"poisson\"):\n",
        "                a = noise_parameter*torch.ones(images.shape)\n",
        "                p = torch.poisson(a)\n",
        "                p_norm = p/p.max()\n",
        "                noisy_images = (images + p_norm).clip(0,1)\n",
        "            images = images.to(device)\n",
        "            noisy_images = noisy_images.to(device)\n",
        "            preds = model(images)\n",
        "            psnr.extend(PSNR(images.cpu().detach(), preds.cpu().detach()))\n",
        "            mse.extend(MSE(images.cpu().detach(), preds.cpu().detach()))\n",
        "        print(f\"Peak Signal to Noise Ratio:   Mean: {np.array(psnr).mean()} || Std: {np.array(psnr).std()}\")\n",
        "        print(f\"Mean Squared Error:   Mean: {np.array(mse).mean()} || Std: {np.array(mse).std()}\")\n",
        "        return np.array(psnr).mean(), np.array(mse).mean()"
      ],
      "metadata": {
        "trusted": true,
        "id": "EM6Im0AkfLmx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, noise_type, noise_parameter, optimizer, train_dataloader, val_dataloader, loss_module, target_type=\"clean\", num_epochs=30):\n",
        "    model.train()\n",
        "    epoch_num = []\n",
        "    mse_train = []\n",
        "    mse_val = []\n",
        "    psnr_train = []\n",
        "    psnr_val = []\n",
        "    mse = 0.0\n",
        "    psnr = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        for images, _ in train_dataloader:\n",
        "            targets = torch.clone(images)\n",
        "            if (noise_type == \"normal\"):\n",
        "                images = (images + torch.normal(0,noise_parameter,images.shape)).clip(0,1)\n",
        "            elif (noise_type == \"bernoulli\"):\n",
        "                a = noise_parameter*torch.ones(images.shape)\n",
        "                images = images*torch.bernoulli(a)\n",
        "            elif (noise_type == \"poisson\"):\n",
        "                a = noise_parameter*torch.ones(images.shape)\n",
        "                p = torch.poisson(a)\n",
        "                p_norm = p/p.max()\n",
        "                images = (images + p_norm).clip(0,1)\n",
        "            if (target_type == \"noisy\"):\n",
        "                if (noise_type == \"normal\"):\n",
        "                    targets = (targets + torch.normal(0,noise_parameter,targets.shape)).clip(0,1)\n",
        "                elif (noise_type == \"bernoulli\"):\n",
        "                    a = noise_parameter*torch.ones(targets.shape)\n",
        "                    targets = targets*torch.bernoulli(a)\n",
        "                elif (noise_type == \"poisson\"):\n",
        "                    a = noise_parameter*torch.ones(targets.shape)\n",
        "                    p = torch.poisson(a)\n",
        "                    p_norm = p/p.max()\n",
        "                    targets = (targets + p_norm).clip(0,1)\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            preds = model(images)\n",
        "            loss = loss_module(preds, targets)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        if (epoch%3 == 0):\n",
        "            print(f\"********EPOCH {epoch+1}:********\")\n",
        "            epoch_num.append(epoch+1)\n",
        "            print(\"Train set:\")\n",
        "            psnr, mse = eval_model(model, train_dataloader, noise_type, noise_parameter)\n",
        "            psnr_train.append(psnr)\n",
        "            mse_train.append(mse)\n",
        "            print(\"Validation set:\")\n",
        "            psnr, mse = eval_model(model, val_dataloader, noise_type, noise_parameter)\n",
        "\n",
        "            psnr_val.append(psnr)\n",
        "            mse_val.append(mse)"
      ],
      "metadata": {
        "trusted": true,
        "id": "xFlbduE8fLmx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"font-size:18px;\">In the training and validation functions I've taken into consideration various noise types to make it easier if we want to generalize a model by training it each time on a different type and with different parameters."
      ],
      "metadata": {
        "id": "2wEfrAuWfLmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normal_ae_mse = DWT2DenoisingModel()\n",
        "normal_optimizer_mse = optim.Adam(normal_ae_mse.parameters(), lr=1e-3)\n",
        "normal_ae_mse = normal_ae_mse.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "zO36qkHIfLmy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "bernoulli_ae = DWT2DenoisingModel()\n",
        "bernoulli_optimizer = optim.Adam(bernoulli_ae.parameters(), lr=1e-3)\n",
        "bernoulli_ae = bernoulli_ae.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "cs7yUYhkfLmy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "poisson_ae = DWT2DenoisingModel()\n",
        "poisson_optimizer = optim.Adam(poisson_ae.parameters(), lr=1e-3)\n",
        "poisson_ae = poisson_ae.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "KglFaNhAfLmy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_model(normal_ae_mse, \"normal\", 0.2, normal_optimizer_mse, train_dataloader, val_dataloader, loss_module)"
      ],
      "metadata": {
        "scrolled": true,
        "tags": [],
        "trusted": true,
        "id": "sxI8zynJfLmy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ae = DWT2DenoisingModel()\n",
        "ae = ae.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "245xA_upfLmy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "normal_ae.eval()"
      ],
      "metadata": {
        "trusted": true,
        "id": "zKEPfHZtfLmy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "images, _ = next(iter(train_dataloader))\n",
        "images = images.float().to(device)\n",
        "output = normal_ae(images)"
      ],
      "metadata": {
        "trusted": true,
        "id": "wLwB-qabfLmz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(images[1].cpu().detach(), normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "G8scyq8YfLmz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "images = (images + torch.normal(0,0.2,images.shape)).clip(0,1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "1JWim8iofLmz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(images[1], normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "2O6zlbsdfLmz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output = normal_ae_mse(images.to(device))"
      ],
      "metadata": {
        "trusted": true,
        "id": "-u6rPi2UfLmz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(output[1].cpu().detach(), normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "AC1pBZjlfLmz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "images, _ = next(iter(val_dataloader))\n",
        "images = images.float().to(device)\n",
        "output = normal_ae_mse(images)"
      ],
      "metadata": {
        "trusted": true,
        "id": "N87hsAYKfLmz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(images[1].cpu().detach(), normalize = False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "o0o8e1nxfLm0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_images = (images + torch.normal(0,0.2,images.shape).to(device)).clip(0,1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "wLkANeC6fLm0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(noisy_images[1].cpu().detach(), normalize = False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "BvyeQb1dfLm0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output = normal_ae_mse(images)"
      ],
      "metadata": {
        "trusted": true,
        "id": "5YO7Q_m6fLm0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(output[1].cpu().detach(), normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "FiffezEsfLm0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "MSE(images, output)"
      ],
      "metadata": {
        "trusted": true,
        "id": "WtA4wt_efLm0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "PSNR(images, output)"
      ],
      "metadata": {
        "trusted": true,
        "id": "7lQmKKhgfLm0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "a = 5*torch.ones(images.shape)\n",
        "p = torch.poisson(a)\n",
        "p_norm = p/p.max()\n",
        "images = (images + p_norm.to(device)).clip(0,1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "CkaFhQxqfLm1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(images[1].cpu().detach(), normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "EfwBazFQfLm1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output = normal_ae_mse(images)"
      ],
      "metadata": {
        "trusted": true,
        "id": "PEGtQZbnfLm1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(output[1].cpu().detach(), normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "9SPsgc8mfLm1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"font-size:18px;\">The model actually gave a good, but quite oversmoothed, result on a Poisson-Noisy image even though it wasn't trained on it."
      ],
      "metadata": {
        "id": "Ewcvo9LHfLm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normal_noisy_ae = autoencoders()\n",
        "normal_noisy_optimizer = optim.Adam(normal_noisy_ae.parameters(), lr=1e-2)\n",
        "normal_noisy_ae = normal_noisy_ae.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "O4TNQUIQfLm1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_model(normal_noisy_ae, \"noisy\", 0.2, normal_noisy_optimizer, train_dataloader, loss_module)"
      ],
      "metadata": {
        "scrolled": true,
        "tags": [],
        "trusted": true,
        "id": "CmEkKOsCfLm1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"font-size:18px;\">Here I actually wanted to try an idea presented by J.Lehtinen et al. in the paper \"Noise2Noise: Learning Image Restoration without Clean Data\" ; basically providing noisy target and the optimization problem would lead the model to find the clean representation based on the hypothesis that the noise is centered."
      ],
      "metadata": {
        "id": "_RcB8euWfLm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = images.float().to(device)\n",
        "output = normal_noisy_ae(images)"
      ],
      "metadata": {
        "trusted": true,
        "id": "riQOFejKfLm2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(images[1].cpu().detach(), normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "VvPmG6i2fLm2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(output[1].cpu().detach(), normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "1CY2qScyfLm3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "images = (images + torch.normal(0,0.2,images.shape).to(device)).clip(0,1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "L1l8tSr_fLm3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(images[1].cpu().detach(), normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "2yui6VhffLm3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output = normal_noisy_ae(images)"
      ],
      "metadata": {
        "trusted": true,
        "id": "b7VqjU9zfLm3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(output[1].cpu().detach(), normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "HX8v60NafLm3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"font-size:18px;\">Unfortunately, after training for a long time (around 6 hours), the model wasn't able to provide the desired result. This can be due to the limited size of the model or the number of the training epochs."
      ],
      "metadata": {
        "id": "y14OXimofLm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normal_noisy_optimizer = optim.Adam(normal_noisy_ae.parameters(), lr=0.005)"
      ],
      "metadata": {
        "trusted": true,
        "id": "1FcE8zLGfLm4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_model(normal_noisy_ae, \"clean\", 0.2, normal_noisy_optimizer, train_dataloader, loss_module, num_epochs = 10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "w4Jz6IfffLm4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(images[1].cpu().detach(), normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "XcKDsUBRfLm4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_images = (images + torch.normal(0,0.2,images.shape)).clip(0,1).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Dkj6pp73fLm4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(noisy_images[1].cpu().detach(), normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "g11-stW4fLm4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output = normal_noisy_ae(noisy_images)"
      ],
      "metadata": {
        "trusted": true,
        "id": "aoXiMncOfLm4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(output[1].cpu().detach(), normalize=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Hl1xWaXlfLm4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"font-size:18px;\">I trained the model this time on clean target (keeping the same model that was trained on noisy data), but it seems like there is no hope with it so we decided to move on from the idea."
      ],
      "metadata": {
        "id": "9k25ozmCfLm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the weights of the first model\n",
        "state_dict = normal_ae_mse.state_dict()\n",
        "print(state_dict)"
      ],
      "metadata": {
        "scrolled": true,
        "tags": [],
        "trusted": true,
        "id": "wNXXXs5ofLm5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loss_module = L1Loss()"
      ],
      "metadata": {
        "trusted": true,
        "id": "pKvPwzUQfLm5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "normal_ae_mae = autoencoders()\n",
        "normal_optimizer_mae = optim.Adam(normal_ae_mae.parameters(), lr=1e-3)\n",
        "normal_ae_mae = normal_ae_mae.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "8d566DEqfLm5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_model(normal_ae_mae, \"normal\", 0.2, normal_optimizer_mae, train_dataloader, val_dataloader, loss_module)"
      ],
      "metadata": {
        "scrolled": true,
        "tags": [],
        "trusted": true,
        "id": "ItJb9cKgfLm5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"font-size:18px;\">We trained the second model (same architecture but different loss function)."
      ],
      "metadata": {
        "id": "1nHY0tF1fLm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = images.float().to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "IMEswEALfLm5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(images[1].cpu().detach(), normalize = False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "CM5jCAlmfLm5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output = normal_ae_mae(images)"
      ],
      "metadata": {
        "trusted": true,
        "id": "tYJ4_Na_fLm5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(output[1].cpu().detach(), normalize = False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "BHgytTFSfLm6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_images = (images.cpu().detach() + torch.normal(0,0.2,images.shape)).clip(0,1).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "t87h466rfLm6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(noisy_images[1].cpu().detach(), normalize = False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "e8sO0WkLfLm6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output = normal_ae_mae(noisy_images)"
      ],
      "metadata": {
        "trusted": true,
        "id": "6-i7zm9GfLm6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(output[1].cpu().detach(), normalize = False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "HFGVTHuUfLm6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load(\"normal_ae_mse_30epochs.tar\")\n",
        "normal_ae_mse = autoencoders()\n",
        "normal_ae_mse.load_state_dict(state_dict)"
      ],
      "metadata": {
        "trusted": true,
        "id": "zHxAy_C2fLm6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "normal_ae_mse = normal_ae_mse.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "RE1gCylmfLm6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output1 = normal_ae_mse(noisy_images)"
      ],
      "metadata": {
        "trusted": true,
        "id": "jt9yuEyefLm6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(output1[1].cpu().detach(), normalize = False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "lwEJkO5tfLm7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = normal_mae.state_dict()"
      ],
      "metadata": {
        "trusted": true,
        "id": "RASJAyv-fLm7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results from the Auto-Encoder Models"
      ],
      "metadata": {
        "tags": [],
        "id": "hSEHhxQSfLm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normal_ae_mse = autoencoders()\n",
        "state_dict = torch.load(\"normal_ae_mse_30epochs.tar\")\n",
        "normal_ae_mse.load_state_dict(state_dict)"
      ],
      "metadata": {
        "trusted": true,
        "id": "I8tzPIc1fLm7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "normal_ae_mse = normal_ae_mse.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "kD_vUepDfLm7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "psnr = []\n",
        "with torch.no_grad():\n",
        "        for i, (images, _) in enumerate(val_dataloader):\n",
        "            noisy_images = (images + torch.normal(0,0.2,images.shape)).clip(0,1)\n",
        "            noisy_images = noisy_images.to(device)\n",
        "            images = images.to(device)\n",
        "            preds = normal_ae_mse(noisy_images)\n",
        "            if (i<4):\n",
        "                print(PSNR(images.cpu().detach(), preds.cpu().detach()))\n",
        "            psnr.extend(PSNR(images.cpu().detach(), preds.cpu().detach()))"
      ],
      "metadata": {
        "trusted": true,
        "id": "D_f4f56XfLm7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mse_psnr = psnr.copy()"
      ],
      "metadata": {
        "trusted": true,
        "id": "yFv_yVZ_fLm7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mse_psnr = np.array(mse_psnr)"
      ],
      "metadata": {
        "trusted": true,
        "id": "1ISPHcb2fLm7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The mean of the PSNR is {mse_psnr.mean()} and the standard deviation of the PSNR is {mse_psnr.std()}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "5wxBtNl3fLm8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean of the PSNR is 31.12668800354004 and the standard deviation of the PSNR is 1.1921919584274292"
      ],
      "metadata": {
        "id": "1ztRgCaxfLm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normal_ae_mae = autoencoders()\n",
        "state_dict = torch.load(\"normal_ae_mae_30epochs.tar\")\n",
        "normal_ae_mae.load_state_dict(state_dict)"
      ],
      "metadata": {
        "trusted": true,
        "id": "xsYnRqV1fLm8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "normal_ae_mae = normal_ae_mae.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "rLFX7_8yfLm8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "psnr = []\n",
        "with torch.no_grad():\n",
        "        for i, (images, _) in enumerate(val_dataloader):\n",
        "            noisy_images = (images + torch.normal(0,0.2,images.shape)).clip(0,1)\n",
        "            noisy_images = noisy_images.to(device)\n",
        "            images = images.to(device)\n",
        "            preds = normal_ae_mae(noisy_images)\n",
        "            if (i<4):\n",
        "                print(PSNR(images.cpu().detach(), preds.cpu().detach()))\n",
        "            psnr.extend(PSNR(images.cpu().detach(), preds.cpu().detach()))"
      ],
      "metadata": {
        "trusted": true,
        "id": "O38_h3oufLm8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mae_psnr = np.array(psnr.copy())\n",
        "print(f\"The mean of the PSNR is {mae_psnr.mean()} and the standard deviation of the PSNR is {mae_psnr.std()}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "QQ9SYCl9fLm8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean of the PSNR is 31.070117950439453 and the standard deviation of the PSNR is 1.2800648212432861"
      ],
      "metadata": {
        "id": "76UulMlYfLm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psnr=[]\n",
        "for i, (images, _) in enumerate(val_dataloader):\n",
        "    noisy_images = (images + torch.normal(0,0.2,images.shape)).clip(0,1)\n",
        "    for j in range(images.shape[0]):\n",
        "        psnr.append(PSNR(images[j,:,:,:].unsqueeze(0), torch.tensor(bm3d.bm3d(noisy_images[j,:,:,:].permute(1,2,0), sigma_psd=30/255, stage_arg=bm3d.BM3DStages.HARD_THRESHOLDING)).permute(2,0,1).unsqueeze(0)))\n",
        "    if (i<4):\n",
        "        print(psnr)"
      ],
      "metadata": {
        "scrolled": true,
        "tags": [],
        "trusted": true,
        "id": "w_33vD-AfLm9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "bm3d_psnr = torch.tensor(psnr.copy())\n",
        "print(f\"The mean of the PSNR is {bm3d_psnr.mean()} and the standard deviation of the PSNR is {bm3d_psnr.std()}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "wpDqzxDifLm9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean of the PSNR is 23.5729346128809 and the standard deviation of the PSNR is 0.4025119048011183\n"
      ],
      "metadata": {
        "id": "5t-0kPpvfLm9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![first_result.png](attachment:2d4d44fd-d242-4052-8bce-d8d76bef175b.png)"
      ],
      "metadata": {
        "id": "Eby2Gcq7fLm9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xp2QBHtZk1Tg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}